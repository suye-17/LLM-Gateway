# LLM Gateway Configuration

server:
  host: "0.0.0.0"
  port: 8080
  read_timeout: "30s"
  write_timeout: "30s"
  idle_timeout: "120s"

database:
  host: "localhost"
  port: 5432
  username: "gateway"
  password: "password"
  database: "gateway"
  max_open_conns: 100
  max_idle_conns: 10

redis:
  host: "localhost"
  port: 6379
  password: ""
  database: 0

auth:
  jwt_secret: "your-jwt-secret-key-change-this-in-production"
  jwt_expiration: "24h"
  enable_api_key: true

logging:
  level: "info"       # debug, info, warn, error
  format: "json"      # json, text
  output: "stdout"    # stdout, stderr, file path

metrics:
  enabled: true
  path: "/metrics"
  port: 9090

# Provider configurations will be added here
providers:
  openai:
    enabled: true
    api_key: "${OPENAI_API_KEY}"
    base_url: "https://api.openai.com/v1"
    timeout: "30s"
    retry_count: 3
    
  anthropic:
    enabled: false
    api_key: "${ANTHROPIC_API_KEY}"
    base_url: "https://api.anthropic.com"
    timeout: "30s"
    retry_count: 3